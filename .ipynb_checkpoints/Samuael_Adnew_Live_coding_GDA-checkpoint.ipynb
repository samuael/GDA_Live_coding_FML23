{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g17Z46tmw2oZ"
   },
   "source": [
    "# GDA Implementation.\n",
    "\n",
    "Implement the Gaussian Discriminant Analysis (GDA) learning algorithm following the steps as discussed in class.\n",
    "\n",
    "INSTRUCTION: Rename your notebook as: <br>\n",
    "`firstName_LastName_Live_coding_GDA.ipynb`.\n",
    "\n",
    "Notes: \n",
    "* Do not use any built-in functions to complete a task;\n",
    "* Do not import additional libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "aT5nlL-QTKwv"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_-lL4Yq9Tbzn",
    "outputId": "30937363-7f7e-4360-e123-b4cdb1ebe441"
   },
   "outputs": [],
   "source": [
    "# Generate data\n",
    "def generate_data():\n",
    "  x, y = make_classification(n_samples= 1000, n_features=3, n_redundant=0, \n",
    "                           n_informative=3, random_state=1, \n",
    "                           n_clusters_per_class=1)\n",
    "  \n",
    "  return x,y\n",
    "\n",
    "x,y= generate_data() # get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "EUgiWLDhUAAK"
   },
   "outputs": [],
   "source": [
    "def split_data(x,y, train_size= 0.8):\n",
    "    # shuffle the data to randomize the train/test split\n",
    "    n, m = x.shape\n",
    "    permutation = np.random.permutation(n)\n",
    "    x = x[permutation]\n",
    "    y=y[permutation]\n",
    "    split_position = int(n*train_size)\n",
    "    return x[:split_position], x[split_position:], y[:split_position], y[split_position:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cr2Akm_A_FcJ",
    "outputId": "2b8f984d-f896-429f-8097-6fa9cba2d7dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 3) (800,) (200, 3) (200,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test= split_data(x, y) # split your data into x_train, x_test, y_train, y_test\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "# print(len(X_train.T[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance(x, mu):  # mu = 1x3 and x= nx3  for a single class | eg. y=0\n",
    "    n, d = x.shape\n",
    "    sigma = np.zeros((d,d))\n",
    "    for di in range(d):\n",
    "        for dx in range(d):\n",
    "            vac = np.zeros(n)\n",
    "            for i in range(n):\n",
    "                vac[i]= (x[i][di]-mu[di])*(x[i][dx]-mu[dx])\n",
    "            sigma[di,dx]=np.mean(vac)\n",
    "    return sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.84310829, 0.02787855, 1.00037396],\n",
       "       [0.02787855, 1.0007055 , 0.05533637],\n",
       "       [1.00037396, 0.05533637, 1.74657168]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covariance(x, x.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.84495325, 0.02790646, 1.00137533],\n",
       "       [0.02790646, 1.00170721, 0.05539176],\n",
       "       [1.00137533, 0.05539176, 1.74832   ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(x, rowvar= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1ocKLDAfceF0"
   },
   "outputs": [],
   "source": [
    "class GDA:\n",
    "  def __init__(self):\n",
    "    ## set mu, phi and sigma to None\n",
    "    self.mu = None\n",
    "    self.phi = None\n",
    "    self.sigma = None\n",
    "    \n",
    "    \n",
    "  def fit(self,x,y):\n",
    "    k=len(np.unique(y)) # Number of class.\n",
    "    m,d=x.shape  # input dim\n",
    "    # m= ... # Number of examples.\n",
    "    self.sigma = np.zeros((k, d, d))\n",
    "    ## Initialize mu, phi and sigma\n",
    "    self.mu,self.phi= self.calc_mus(x,y,k)#: kxd, i.e., each row contains an individual class mu.\n",
    "    for ki in range(k):\n",
    "        indexes = np.where(y==ki)\n",
    "        self.sigma[ki]= self.covariance(x[indexes], self.mu[ki])\n",
    "    #: kxdxd, i.e., each row contains an individual class sigma.\n",
    "\n",
    "\n",
    "  def predict_proba(self,x):\n",
    "    n,d= x.shape\n",
    "    k_class= 2 # Number of classes we have in our case it's k = 2\n",
    "    vals = []\n",
    "    p = np.zeros((n,k_class))\n",
    "    for b in range(k_class):\n",
    "        for i in range(n):\n",
    "#             print(1/(2*np.pi)**(d/2)*np.sqrt(np.linalg.det(self.sigma[b])))\n",
    "            p[i,b]=(1/(2*np.pi)**(d/2)*np.sqrt(np.linalg.det(self.sigma[b])))*np.exp(-((x[i]-self.mu[b]).T@np.linalg.inv(self.sigma[b])@(x[i]-self.mu[b])))\n",
    "    return p\n",
    "    \n",
    "  def covariance(self, x, mu):  # mu = 1x3 and x= nx3  for a single class | eg. y=0\n",
    "    n, d = x.shape\n",
    "    sigma = np.zeros((d,d))\n",
    "    for di in range(d):\n",
    "        for dx in range(d):\n",
    "            vac = np.zeros(n)\n",
    "            for i in range(n):\n",
    "                vac[i]= (x[i][di]-mu[di])*(x[i][dx]-mu[dx])\n",
    "            sigma[di,dx]=np.mean(vac)\n",
    "    return sigma\n",
    "    # Easy way: cov= np.cov(x, rowvar=0) but do not use it. One can use it to assess his/her result.\n",
    "\n",
    "  def calc_mus(self,x, y, k):\n",
    "    n, d = x.shape\n",
    "    self.mu = np.zeros((k, d))\n",
    "    self.phi = np.zeros((k, d))\n",
    "    for i in range(k):\n",
    "        indexes = np.where(y==i)\n",
    "        x_transposed = x[indexes].T\n",
    "        for di in range(d):\n",
    "            self.mu[i, di]= np.mean(x_transposed[di])\n",
    "            self.phi[i,di] = np.sum(x_transposed[di])/len(x)\n",
    "    return self.mu, self.phi\n",
    "\n",
    "  def predict(self,x):\n",
    "    y_pred = self.predict_proba(x)\n",
    "    return y_pred.argmax(axis=1)\n",
    "  \n",
    "  def accuracy(self, y, ypreds):\n",
    "    return np.mean(np.where(y==ypreds,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "l_qO0Yp1c3Is"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975\n"
     ]
    }
   ],
   "source": [
    "model= GDA()\n",
    "model.calc_mus(x, y, 2)\n",
    "\n",
    "sigma = np.zeros((2, 3, 3))\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "# x_pred=model.predict_proba(X_test)\n",
    "ya= model.predict(X_test)\n",
    "acc=model.accuracy(ya, y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "NKY1eojY1l4e"
   },
   "outputs": [],
   "source": [
    "yproba= model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "D4clV6PK1UJK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypreds= model.predict(X_test)\n",
    "ypreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "id": "QgG1xPUg1ULw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.5"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.accuracy(y_test, ypreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "8cvRcUO2rtKo"
   },
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "  '''\n",
    "  The goal of this class is to create a LogisticRegression class, \n",
    "  that we will use as our model to classify data point into a corresponding class\n",
    "  '''\n",
    "  def __init__(self,lr,n_epochs):\n",
    "    self.lr = lr\n",
    "    self.n_epochs = n_epochs\n",
    "    self.train_losses = []\n",
    "    self.w = None\n",
    "    self.weight = []\n",
    "\n",
    "  def add_ones(self, x):\n",
    "    one = np.ones((x.shape[0],1))\n",
    "    return np.hstack((one,x))\n",
    "\n",
    "  def sigmoid(self, x):\n",
    "    return 1/(1+np.exp(-x@self.w))\n",
    "\n",
    "\n",
    "  def cross_entropy(self, x, y_true):\n",
    "    y_pred = self.sigmoid(x)\n",
    "    loss = -np.mean(y_true*np.log(y_pred)+(1-y_true)*np.log(1-y_pred))\n",
    "    return loss\n",
    "  \n",
    "  def predict_proba(self,x):  #This function will use the sigmoid function to compute the probalities\n",
    "    x= self.add_ones(x)\n",
    "    proba = self.sigmoid(x)\n",
    "    return proba\n",
    "\n",
    "  def predict(self,x):\n",
    "    probas = self.predict_proba(x)\n",
    "    output = [0 if p<0.5 else 1 for p in probas]#np.where(probas>=0.5, 1, 0)      #convert the probalities into 0 and 1 by using a treshold=0.5\n",
    "    return output\n",
    "\n",
    "  def fit(self,x,y):\n",
    "    # Add ones to x\n",
    "    x=self.add_ones(x)\n",
    "\n",
    "    # reshape y if needed\n",
    "    y=y.reshape(-1,1)\n",
    "\n",
    "    # Initialize w to zeros vector >>> (x.shape[1])\n",
    "    self.w=np.zeros((x.shape[1],1))\n",
    "\n",
    "    for epoch in range(self.n_epochs):\n",
    "      # make predictions\n",
    "      ypred = self.sigmoid(x)\n",
    "\n",
    "      #compute the gradient\n",
    "      dl = (-1/x.shape[0])*(x.T@(y-ypred))\n",
    "\n",
    "      self.w=self.w-self.lr*dl\n",
    "\n",
    "      #Compute and append the training loss in a list\n",
    "      loss = self.cross_entropy(x,y)\n",
    "      self.train_losses.append(loss)\n",
    "\n",
    "      if epoch%1000 == 0:\n",
    "        print(f'loss for epoch {epoch}  : {loss}')\n",
    "\n",
    "  def accuracy(self,y_true, y_pred):\n",
    "    return np.mean(y_true==y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch 0  : 0.6883021362359153\n",
      "loss for epoch 1000  : 0.20255779952567984\n",
      "loss for epoch 2000  : 0.17899343787682362\n",
      "loss for epoch 3000  : 0.17006949577964947\n",
      "loss for epoch 4000  : 0.16516801225313926\n",
      "loss for epoch 5000  : 0.1619843019461709\n",
      "loss for epoch 6000  : 0.15971881694043455\n",
      "loss for epoch 7000  : 0.15801650441305928\n",
      "loss for epoch 8000  : 0.15669207434506577\n",
      "loss for epoch 9000  : 0.1556369975813339\n"
     ]
    }
   ],
   "source": [
    "Lmodel = LogisticRegression(0.01,n_epochs=10000)\n",
    "Lmodel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypreds= Lmodel.predict(X_test)\n",
    "Lmodel.accuracy(y_test,ypreds)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
